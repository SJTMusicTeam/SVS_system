# public hts data path
train_align: data/alignment/train
train_pitch: data/pitch_beat_extraction/train
train_wav: data/wav_info/train
val_align: data/alignment/dev
val_pitch: data/pitch_beat_extraction/dev
val_wav: data/wav_info/dev


model_save_dir: exp/rnn

resume: True
mask_free: False
use_asr_post: False
sampling_rate: 22050
nfft: 2048
feat_dim: 1025

frame_length: 0.05
frame_shift: 0.0125
model_type: LSTM
max_epochs: 200
batchsize: 4
num_workers: 10
hidden_size: 512
embedding_size: 512
num_rnn_layers: 3
num_frames: 500
char_max_len: 100
optimizer: adam
lr: 0.001
phone_size: 68
seed: 777
gpu_id: -1

normalize: True # for utterence normalize
# collect_stats: True

scheduler: ReduceLROnPlateau

# collect_stats: True

# model_save_dir: exp/2020_1_21_rnn_norm_perp/model
# stats_file: exp/2020_1_21_rnn_norm_perp/model/feats_stats.npz
# stats_mel_file: exp/2020_1_21_rnn_norm_perp/model/feats_mel_stats.npz

double_mel_loss: False
# perceptual_loss: 1e-2

accumulation_steps: 1
auto_select_gpu: False
n_mels: 80

train_step_log: 20
dev_step_log: 2

# vocoder parameters
voc_rnn_dims: 512
voc_fc_dims: 512
voc_bits: 9
voc_pad: 2
# voc_upsample_factors: (5, 5, 11)
voc_upsample_factors_0: 5
voc_upsample_factors_1: 5
voc_upsample_factors_2: 11
voc_compute_dims: 128
voc_res_out_dims: 128
voc_res_blocks: 10
hop_length: 275
voc_mode: "MOL"
wavernn_voc_model: downloads/model/wavernn/latest_weights.pyt

