# public kiritan data
train_align: data/alignment/train
train_pitch: data/pitch_beat_extraction/train
train_wav: data/wav_info/train
val_align: data/alignment/dev
val_pitch: data/pitch_beat_extraction/dev
val_wav: data/wav_info/dev

# standard: 4
# sing_quality: conf/sing_quality.csv

model_type: LSTM
# model_save_dir: exp/2020_1_21_rnn_norm_perp/model
# stats_file: exp/2020_1_21_rnn_norm_perp/model/feats_stats.npz
# stats_mel_file: exp/2020_1_21_rnn_norm_perp/model/feats_mel_stats.npz

normalize: True
double_mel_loss: False
# perceptual_loss: 1e-2


accumulation_steps: 1
auto_select_gpu: False
gpu_id: 1

max_epochs: 150

batchsize: 5
num_workers: 5

mask_free: False
use_asr_post: False
sampling_rate: 22050
nfft: 2048
feat_dim: 1025
n_mels: 80

frame_length: 0.05
frame_shift: 0.0125

hidden_size: 256
embedding_size: 256
num_rnn_layers: 3
num_frames: 500
char_max_len: 100
optimizer: adam
lr: 0.001
phone_size: 68
seed: 777

train_step_log: 20
dev_step_log: 2

# vocoder parameters
voc_rnn_dims: 512
voc_fc_dims: 512
voc_bits: 9
voc_pad: 2
# voc_upsample_factors: (5, 5, 11)
voc_upsample_factors_0: 5
voc_upsample_factors_1: 5
voc_upsample_factors_2: 11
voc_compute_dims: 128
voc_res_out_dims: 128
voc_res_blocks: 10
hop_length: 275
voc_mode: "MOL"
wavernn_voc_model: downloads/model/wavernn/latest_weights.pyt
